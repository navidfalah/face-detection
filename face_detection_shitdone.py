# -*- coding: utf-8 -*-
"""face_detection_shitdone.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1msMQUiZqFDWUIRKgh_e2CQfnGWOwmkTj
"""

!python -m pip install pyyaml==5.1
import sys, os, distutils.core

!git clone 'https://github.com/facebookresearch/detectron2'
dist = distutils.core.run_setup("./detectron2/setup.py")
!python -m pip install {' '.join([f"'{x}'" for x in dist.install_requires])}
sys.path.insert(0, os.path.abspath('./detectron2'))

import torch, detectron2
!nvcc --version
TORCH_VERSION = ".".join(torch.__version__.split(".")[:2])
CUDA_VERSION = torch.__version__.split("+")[-1]
print("torch: ", TORCH_VERSION, "; cuda: ", CUDA_VERSION)
print("detectron2:", detectron2.__version__)

# Commented out IPython magic to ensure Python compatibility.
import torch, torchvision
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

import glob
import os
import ntpath
import numpy as np
import cv2
import random
import itertools
import pandas as pd
from tqdm import tqdm
import urllib
import json
import PIL.Image as Image

from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor, DefaultTrainer
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer, ColorMode
from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader
from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.structures import BoxMode

import seaborn as sns
from pylab import rcParams
import matplotlib.pyplot as plt
from matplotlib import rc

# %matplotlib inline
# %config InlineBackend.figure_format='retina'

sns.set(style='whitegrid', palette='muted', font_scale=1.2)

HAPPY_COLORS_PALETTE = ["#01BEFE", "#FFDD00", "#FF7D00", "#FF006D", "#ADFF02", "#8F00FF"]

sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))
rcParams['figure.figsize'] = 12, 8
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)

!gdown --id 1K79wJgmPTWamqb04Op2GxW0SW9oxw8KS

faces_df = pd.read_json('face_detection.json', lines=True)

faces_df.head()

import numpy as np
import requests
from tqdm import tqdm
from PIL import Image
from io import BytesIO



response = requests.get(faces_df[0]['content'])

import os
import pandas as pd
import urllib.request
from PIL import Image
from tqdm import tqdm

# Ensure the faces directory exists
os.makedirs("faces", exist_ok=True)

# Initialize an empty dataset
dataset = []

# Add headers for HTTP request
headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"}

# Iterate over the DataFrame rows
for index, row in tqdm(faces_df.iterrows(), total=faces_df.shape[0]):
    try:
        # Download the image from the URL
        img_url = row["content"]
        req = urllib.request.Request(img_url, headers=headers)
        print(img_url)
        img_response = urllib.request.urlopen(req)

        # Open and process the image
        img = Image.open(img_response)
        img = img.convert('RGB')  # Convert to RGB format

        # Generate an image file name
        image_name = f'face_{index}.jpeg'

        # Save the image to the 'faces' directory
        img.save(f'faces/{image_name}', "JPEG")

        # Extract annotations
        annotations = row['annotation']
        for an in annotations:
            data = {}

            # Extract image dimensions and bounding box points
            width = an['imageWidth']
            height = an['imageHeight']
            points = an['points']

            # Prepare the dataset entry
            data['file_name'] = image_name
            data['width'] = width
            data['height'] = height
            data["x_min"] = int(round(points[0]["x"] * width))
            data["y_min"] = int(round(points[0]["y"] * height))
            data["x_max"] = int(round(points[1]["x"] * width))
            data["y_max"] = int(round(points[1]["y"] * height))
            data['class_name'] = 'face'

            # Append the data entry to the dataset
            dataset.append(data)
    except Exception as e:
        print(f"Error processing row {index}: {e}")

# Create a DataFrame from the dataset
df = pd.DataFrame(dataset)

# Save the DataFrame to a CSV file for future use
df.to_csv("faces_dataset.csv", index=False)

# Output some information about the dataset
print(f"Unique file names: {df.file_name.unique().shape[0]}, Total annotations: {df.shape[0]}")

! wget 	http://com.dataturks.a96-i23.open.s3.amazonaws.com/2c9fafb064277d86016431e33e4e003d/8186c3d1-e9d4-4550-8ec1-a062a7628787___0-26.jpg

wget --header="User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36" "http://com.dataturks.a96-i23.open.s3.amazonaws.com/2c9fafb064277d86016431e33e4e003d/8186c3d1-e9d4-4550-8ec1-a062a7628787___0-26.jpg" -O faces/0-26.jpg

!mkdir -p faces
!wget --header="User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36" \
"http://com.dataturks.a96-i23.open.s3.amazonaws.com/2c9fafb064277d86016431e33e4e003d/8186c3d1-e9d4-4550-8ec1-a062a7628787___0-26.jpg" -O faces/0-26.jpg

import os
import requests
from tqdm import tqdm

# Ensure the faces directory exists
os.makedirs("faces", exist_ok=True)

# Function to download images
def download_image(url, output_path):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    try:
        response = requests.get(url, headers=headers, stream=True)
        if response.status_code == 200:
            with open(output_path, 'wb') as f:
                for chunk in response.iter_content(1024):
                    f.write(chunk)
        else:
            print(f"Failed to download {url}: HTTP {response.status_code}")
    except Exception as e:
        print(f"Error downloading {url}: {e}")

# Loop through the URLs and download
for index, url in tqdm(enumerate(faces_df['content'].tolist()), total=len(faces_df)):
    output_path = os.path.join("faces", f"face_{index}.jpg")
    download_image(url, output_path)

